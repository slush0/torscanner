* Goal of proposed script is to check data consistency on all Tor network exit nodes.
* It checks only unencrypted traffic on exit nodes (so not HTTPS, FTPS, SSH etc),
* cause on encrypted traffic, there is no (real) possibility to modify content.
* Because script infrastructure is pluggable, there should be easy to extend
* functionality by adding plugin for new protocol.
*
* Author of this proposal: slush, Léta Páně 2008

Algorithms:
===========

first phase - preparation:
--------------------------
* Overview: In this step, script ask each plugin for internet resource,
* which is able to parse/check (html page, ftp file, ...).
* After that, web spider will start searching for these resources on
* Internet (Using Google as start point).
* Spider will stop after reaching limits on links per site, max files or bytes
* downloaded per rule etc.
* Vocabulary:
* Link - address to any internet resource
* Link bucket - queue of links to download by spider
* File - downloaded resource
* Content - content of file
* Whitelist
* Checklist - list of links to download thru Tor nodes
load web spider conf (max links, max links per site, max time, max bytes)
load whitelist (from file, from conf, ...)
checklist = []
add links from whitelist to link bucket
while link in bucket:
	select link from bucket (queue)
	if exceed "links per site" for this site:
		remove link from bucket
		skip to next link
	if resource seems to be any HTTP content (protocol?):
		download HEADERS of resource
		add headers to cache (for execution phase)
		if resource is html page (Content-Type):
			download file and parse content (TODO)
			get links from page to link bucket
	else (not HTTP content):
		headers = empty
	for each plugin:
		skip plugin, if its number of files or bytes reached limits
		if link matches to plugin rules (protocol, url, headers)
			add link to checklist
	remove link from bucket
	if spider limits reached (max time, bytes), break
	if limits on every plugins reached, break
save checklist

second phase - execution:
-------------------------
load conf (max time, max bytes)
load checklist
load plugins
connect to tor controller
connect to tor socks proxy
get list of all routers
exits = select nodes with flags: Exit, Running (?), Valid (?)
relays = select nodes with flags: Running, Uptime > 1 day
for each link in checklist:
	if resource seems to be any HTTP content (protocol?):
		download HEADERS of resource
for each exit node:
	while not valid circuit or tries > 3:
		create 2node circuit "random relay, exit node"
	nodebucket = checklist
	while link in nodebucket:
		for each plugin:
			if link matches to plugin rules (protocol, url, headers):
				call plugin._analyze(protocol, url, headers)
				save to struct [link][exitnode]
	if spider limits reached (max time, bytes), break
	if limits on every plugins reached, break
		

third phase - analysis:
-----------------------
* Overview: Target of this phase is to cross-check plugin results of each matched file
* across exit nodes. That means that there is no sharp border between valid and invalid exit node,
* but some probability level of failure. When 99% exit nodes returns the same
* content of page and the last one returns something modified, there is probably problem.
* On other side, when only 20% nodes returns the same content, there is big probability, that
* "problem" is on content provider side (dynamic links, time-specific links etc).
* Each script user should consider weights of all aspect and select border level regards
* his own usage of Tor.
* Testing page: http://slush.cz/tortest.php

Vstup: stromova struktura hashu pro kazdou stranku.
	Stejna stranka stazena pres vsechny exit nody, tj. X kopii teze stranky.
Pro kazdy hash spocitam jeho index (nezavisle na poradi, nezavisle na hloubce).
	Hash vyjadruje procento zastoupeni hashe v ostatnich strankach.
	0 = hash se v ostatnich strankach nevyskytuje.
	1 = hash se vyskytuje ve vsech ostatnich strankach.
Vypoctu vahu (vyznamnost) kazdeho indexu (hashe).
	Index bez potomku (nejhlubsi hash) ma vahu 1.
	Index s potomky je soucin vazenych *indexu* potomku. (index potomku = index*vaha)

Jak vyresit chybejici hashe?

Classes:
========
Protocol - implements top-level class for known internet services (HTTP, FTP, SSH)
<XXX>Protocol - has to contain method to retrieve protocol-specific content, eg. SSH.
